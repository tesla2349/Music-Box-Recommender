{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Read datasets: play_ds, down_ds\n",
    "df_play = pd.read_csv('../data/play_ds.csv', encoding = \"latin1\")\n",
    "df_down = pd.read_csv('../data/down_ds.csv')\n",
    "\n",
    "# Select relevant features\n",
    "df_play = df_play[['uid','song_id','play_time']]\n",
    "df_down = df_down[['uid','song_id','date']]\n",
    "\n",
    "# Feature types conversion: play data\n",
    "df_play.play_time = pd.to_numeric(df_play.play_time, errors='coerce')\n",
    "df_play.song_id = pd.to_numeric(df_play.song_id, errors='coerce')\n",
    "\n",
    "# Dropna\n",
    "df_play.dropna(inplace=True)\n",
    "\n",
    "# Add up play freqs\n",
    "df_play_2 = df_play.groupby(['uid','song_id']).sum()\n",
    "\n",
    "# Drop infrequently played songs: bucket level=5\n",
    "dropped = df_play_2[df_play_2.play_time<5]\n",
    "df_play_2 = df_play_2.drop(dropped.index)\n",
    "df_play_2.reset_index(inplace=True)\n",
    "\n",
    "# Feature types conversion: download data\n",
    "df_down.uid = pd.to_numeric(df_down.uid, errors='coerce')\n",
    "df_down.song_id = pd.to_numeric(df_down.song_id, errors='coerce')\n",
    "df_down.date = pd.to_datetime(df_down.date, errors='coerce')\n",
    "\n",
    "# dropna\n",
    "df_down.dropna(inplace=True)\n",
    "\n",
    "# Add up download freqs\n",
    "df_down_2 = df_down.groupby(['uid','song_id']).count()\n",
    "\n",
    "# Drop infrequently downloaded songs: bucket level=2\n",
    "df_down_2 = df_down_2[df_down_2.date>1]\n",
    "df_down_2.reset_index(inplace=True)\n",
    "\n",
    "# Rename columns\n",
    "df_play_2.rename(columns={'play_time':'freq'},inplace=True)\n",
    "df_down_2.rename(columns={'date':'freq'},inplace=True)\n",
    "\n",
    "# Concat the two dataframes\n",
    "df_result = pd.concat([df_play_2,df_down_2])\n",
    "\n",
    "# Add up play and download freqs\n",
    "df_result = df_result.groupby(['uid','song_id']).sum().reset_index()\n",
    "\n",
    "# Set the implicit ratings\n",
    "df_result.rename(columns={'freq':'im_rating'},inplace=True)\n",
    "df_result.im_rating = 1\n",
    "\n",
    "# Re-encode uid, song_id\n",
    "df_result.uid = df_result.uid.astype(str)\n",
    "df_result.song_id = df_result.song_id.astype(str)\n",
    "df_result.uid = pd.Categorical(df_result.uid).codes\n",
    "df_result.song_id = pd.Categorical(df_result.song_id).codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the ratings matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<61574x374635 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 0 stored elements in LInked List format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import sparse\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from time import time\n",
    "highest_user_id = df_result.uid.max()\n",
    "highest_song_id = df_result.song_id.max()\n",
    "ratings_mat = sparse.lil_matrix((highest_user_id, highest_song_id))\n",
    "ratings_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, row in df_result.iterrows():\n",
    "    ratings_mat[row.uid-1, row.song_id-1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "utility_mat = ratings_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## popularity-based recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pr = df_result.sort_values(by=['im_rating'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([301934,      1, 277882, 143431, 296477,      0, 244773, 240054,\n",
       "       163227,  71599], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 10 songs\n",
    "recommend_songs = df_pr.song_id.values[:10]\n",
    "recommend_songs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## item-item based recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Item-Item Similarity Matrix\n",
    "item_sim_mat = cosine_similarity(utility_mat.T)\n",
    "least_to_most_sim_indexes = np.argsort(item_sim_mat, axis=1)\n",
    "\n",
    "# Neighborhoods\n",
    "neighborhood_size = 75\n",
    "neighborhoods = least_to_most_sim_indexes[:, -neighborhood_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's pick a lucky user\n",
    "user_id = 100\n",
    "n_users = utility_mat.shape[0]\n",
    "n_items = utility_mat.shape[1]\n",
    "\n",
    "start_time = time()\n",
    "items_rated_by_this_user = ratings_mat[user_id].nonzero()[1]\n",
    "# Just initializing so we have somewhere to put rating preds\n",
    "out = np.zeros(n_items)\n",
    "for item_to_rate in range(n_items):\n",
    "    relevant_items = np.intersect1d(neighborhoods[item_to_rate],\n",
    "                                    items_rated_by_this_user,\n",
    "                                    assume_unique=True)  # assume_unique speeds up intersection op\n",
    "    out[item_to_rate] = ratings_mat[user_id, relevant_items] * \\\n",
    "        item_sim_mat[item_to_rate, relevant_items] / \\\n",
    "        item_sim_mat[item_to_rate, relevant_items].sum()\n",
    "\n",
    "\n",
    "pred_ratings = np.nan_to_num(out)\n",
    "print(pred_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommend n songs\n",
    "n = 10\n",
    "\n",
    "# Get item indexes sorted by predicted rating\n",
    "item_index_sorted_by_pred_rating = list(np.argsort(pred_ratings))[::-1]\n",
    "\n",
    "# Find items that have been rated by user\n",
    "items_rated_by_this_user = ratings_mat[user_id].nonzero()[1]\n",
    "\n",
    "# We want to exclude the items that have been rated by user\n",
    "unrated_items_by_pred_rating = [item for item in item_index_sorted_by_pred_rating\n",
    "                                if item not in items_rated_by_this_user]\n",
    "\n",
    "unrated_items_by_pred_rating[:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## matrix factorization-based recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61574, 200) (200, 374635)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "def fit_uvd(M,k):\n",
    "    svd = TruncatedSVD(n_components=k, n_iter=10, random_state=0)\n",
    "    svd.fit(M)\n",
    "\n",
    "    V = svd.components_\n",
    "    U = svd.transform(M)\n",
    "    return U,V, svd\n",
    "\n",
    "# decompose\n",
    "U,V,svd = fit_uvd(ratings_mat,200)\n",
    "print(U.shape,V.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruct\n",
    "ratings_mat_fitted = U.dot(V) # U*V\n",
    "errs = np.array((ratings_mat-ratings_mat_fitted).flatten()).squeeze()\n",
    "mask = np.array((ratings_mat.todense()).flatten()).squeeze()>0\n",
    "\n",
    "mse = np.mean(errs[mask]**2)\n",
    "average_abs_err = abs(errs[mask]).mean()\n",
    "print(mse)\n",
    "print(average_abs_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[124874,\n",
       " 124869,\n",
       " 124863,\n",
       " 124864,\n",
       " 124865,\n",
       " 124866,\n",
       " 124867,\n",
       " 124868,\n",
       " 124870,\n",
       " 124873]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get recommendations for one user\n",
    "user_id = 100\n",
    "n = 10\n",
    "\n",
    "pred_ratings = np.squeeze(np.asarray(ratings_mat[user_id,:].todense()))\n",
    "item_index_sorted_by_pred_rating = list(np.argsort(pred_ratings))[::-1]\n",
    "\n",
    "items_rated_by_this_user = ratings_mat[user_id].nonzero()[1]\n",
    "\n",
    "unrated_items_by_pred_rating = [item for item in item_index_sorted_by_pred_rating\n",
    "                                if item not in items_rated_by_this_user]\n",
    "\n",
    "unrated_items_by_pred_rating[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
